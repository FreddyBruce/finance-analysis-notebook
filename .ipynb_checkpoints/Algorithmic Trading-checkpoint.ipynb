{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithmic Trading\n",
    "## Introduction\n",
    "Technology has become an asset in finance: financial institutions are now evolving to technology companies rather than just staying occupied with just the financial aspect: besides the fact that technology brings about innovation the speeds and can help to gain a competitive advantage, the speed and frequency of financial transactions, together with the large data volumes, makes that financial institutions’ attention for technology has increased over the years and that technology has indeed become a main enabler in finance.\n",
    "\n",
    "This notebook introduces how to implement some algorithmic trading strategies in Python.\n",
    "\n",
    "### Stocks & Trading\n",
    "When a company wants to grow and undertake new projects or expand, it can issue stocks to raise capital. A stock represents a share in the ownership of a company and is issued in return for money. Stocks are bought and sold: buyers and sellers trade existing, previously issued shares. The price at which stocks are sold can move independent of the company’s success: the prices instead reflect supply and demand. This means that, whenever a stock is considered as ‘desirable’, due to a success, popularity, … the stock price will go up.\n",
    "\n",
    "Note that stocks are not exactly the same as bonds, which is when companies raise money through borrowing, either as a loan from a bank or by issuing debt.\n",
    "\n",
    "As you just read, buying and selling or trading is essential when you’re talking about stocks, but certainly not limited to it: trading is the act of buying or selling an asset, which could be financial security, like stock, a bond or a tangible product, such as gold or oil.\n",
    "\n",
    "Stock trading is then the process of the cash that is paid for the stocks is converted into a share in the ownership of a company, which can be converted back to cash by selling, and this all hopefully with a profit. Now, to achieve a profitable return, you either go long or short in markets: you either by shares thinking that the stock price will go up to sell at a higher price in the future, or you sell your stock, expecting that you can buy it back at a lower price and realize a profit. When you follow a fixed plan to go long or short in markets, you have a trading strategy.\n",
    "\n",
    "Developing a trading strategy is something that goes through a couple of phases, just like when you, for example, build machine learning models: you formulate a strategy and specify it in a form that you can test on your computer, you do some preliminary testing or backtesting, you optimize your strategy and lastly, you evaluate the performance and robustness of your strategy.\n",
    "\n",
    "Trading strategies are usually verified by backtesting: you reconstruct, with historical data, trades that would have occurred in the past using the rules that are defined with the strategy that you have developed. This way, you can get an idea of the effectiveness of your strategy and you can use it as a starting point to optimize and improve your strategy before applying it to real markets. Of course, this all relies heavily on the underlying theory or belief that any strategy that has worked out well in the past will likely also work out well in the future, and, that any strategy that has performed poorly in the past will likely also do badly in the future.\n",
    "\n",
    "### Time Series Data\n",
    "A time series is a sequence of numerical data points taken at successive equally spaced points in time. In investing, a time series tracks the movement of the chosen data points, such as the stock price, over a specified period of time with data points recorded at regular intervals.\n",
    "\n",
    "However, what you’ll often see when you’re working with stock data is not just two columns, that contain period and price observations, but most of the times, you’ll have five columns that contain observations of the period and the opening, high, low and closing prices of that period. This means that, if your period is set at a daily level, the observations for that day will give you an idea of the opening and closing price for that day and the extreme high and low price movement for a particular stock during that day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Basics For Finance: Pandas\n",
    "\n",
    "### Importing Data\n",
    "The `pandas-datareader` package allows for reading in data from sources such as Google, Yahoo! Finance, World Bank,…\n",
    "\n",
    "Here I am pulling apple stock from IEX, which provides historical prices for upto 5 years:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5y\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-10-01</th>\n",
       "      <td>94.4247</td>\n",
       "      <td>94.5186</td>\n",
       "      <td>92.6506</td>\n",
       "      <td>93.1011</td>\n",
       "      <td>51491286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-10-02</th>\n",
       "      <td>93.1856</td>\n",
       "      <td>94.0774</td>\n",
       "      <td>92.0310</td>\n",
       "      <td>93.7770</td>\n",
       "      <td>47757828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-10-03</th>\n",
       "      <td>93.3452</td>\n",
       "      <td>94.0680</td>\n",
       "      <td>92.9697</td>\n",
       "      <td>93.5142</td>\n",
       "      <td>43469585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-10-06</th>\n",
       "      <td>93.8239</td>\n",
       "      <td>94.4810</td>\n",
       "      <td>93.3264</td>\n",
       "      <td>93.5142</td>\n",
       "      <td>37051182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-10-07</th>\n",
       "      <td>93.3358</td>\n",
       "      <td>93.9835</td>\n",
       "      <td>92.6787</td>\n",
       "      <td>92.6975</td>\n",
       "      <td>42094183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               open     high      low    close    volume\n",
       "date                                                    \n",
       "2014-10-01  94.4247  94.5186  92.6506  93.1011  51491286\n",
       "2014-10-02  93.1856  94.0774  92.0310  93.7770  47757828\n",
       "2014-10-03  93.3452  94.0680  92.9697  93.5142  43469585\n",
       "2014-10-06  93.8239  94.4810  93.3264  93.5142  37051182\n",
       "2014-10-07  93.3358  93.9835  92.6787  92.6975  42094183"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas_datareader import data as pdr\n",
    "import fix_yahoo_finance\n",
    "\n",
    "start=datetime.datetime(2014, 10, 1)\n",
    "end=datetime.datetime(2018, 1, 1)\n",
    "\n",
    "appl = pdr.DataReader('AAPL', 'iex',start,end)\n",
    "appl.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative to `pandas_datareader` is Quandl:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "LimitExceededError",
     "evalue": "(Status 429) (Quandl Error QELx01) You have exceeded the anonymous user limit of 50 calls per day. To make more calls today, please register for a free Quandl account and then include your API key with your requests.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLimitExceededError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-e28fa0e107fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mquandl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0maapl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquandl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"WIKI/AAPL\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_date\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"2006-10-01\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_date\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"2012-01-01\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0maapl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.4_2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/quandl/get.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(dataset, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdataset_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'column_index'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'column_index'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdataset_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'column_index'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'code'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle_column_not_found\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0;31m# Array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.4_2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/quandl/model/dataset.py\u001b[0m in \u001b[0;36mdata\u001b[0;34m(self, **options)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mupdated_options\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUtil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mupdated_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mNotFoundError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhandle_not_found_error\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.4_2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/quandl/operations/list.py\u001b[0m in \u001b[0;36mall\u001b[0;34m(cls, **options)\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUtil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstructed_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mresponse_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mUtil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_dates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.4_2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/quandl/connection.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(cls, http_verb, url, **options)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mabs_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'%s/%s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mApiConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_base\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_verb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabs_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.4_2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/quandl/connection.py\u001b[0m in \u001b[0;36mexecute_request\u001b[0;34m(cls, http_verb, url, **options)\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m                 \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_api_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.4_2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/quandl/connection.py\u001b[0m in \u001b[0;36mhandle_api_error\u001b[0;34m(cls, resp)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mklass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_klass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode_letter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQuandlError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mLimitExceededError\u001b[0m: (Status 429) (Quandl Error QELx01) You have exceeded the anonymous user limit of 50 calls per day. To make more calls today, please register for a free Quandl account and then include your API key with your requests."
     ]
    }
   ],
   "source": [
    "import quandl\n",
    "aapl = quandl.get(\"WIKI/AAPL\", start_date=\"2006-10-01\", end_date=\"2012-01-01\")\n",
    "aapl.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working With Time Series Data\n",
    "The data was read into a pandas dataframe, so all the normal functions are available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the index \n",
    "aapl.index\n",
    "\n",
    "# Inspect the columns\n",
    "aapl.columns\n",
    "\n",
    "# Select only the last 10 observations of `Close`\n",
    "ts = aapl['Close'][-10:]\n",
    "\n",
    "# Check the type of `ts` \n",
    "type(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the first rows of November-December 2006\n",
    "print(aapl.loc[pd.Timestamp('2006-11-01'):pd.Timestamp('2006-12-31')].head())\n",
    "\n",
    "# Inspect the first rows of 2007 \n",
    "print(aapl.loc['2007'].head())\n",
    "\n",
    "# Inspect November 2006\n",
    "print(aapl.iloc[22:43])\n",
    "\n",
    "# Inspect the 'Open' and 'Close' values at 2006-11-01 and 2006-12-01\n",
    "print(aapl.iloc[[22,43], [0, 3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample 20 rows\n",
    "sample = aapl.sample(20)\n",
    "\n",
    "# Print `sample`\n",
    "print(sample)\n",
    "\n",
    "# Resample to monthly level \n",
    "monthly_aapl = aapl.resample('M')\n",
    "\n",
    "# Print `monthly_aapl`\n",
    "print(monthly_aapl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column `diff` to `aapl` \n",
    "aapl['diff'] = aapl.Open - aapl.Close\n",
    "\n",
    "# Delete the new `diff` column\n",
    "del aapl['diff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Matplotlib's `pyplot` module as `plt`\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the closing prices for `aapl`\n",
    "aapl['Close'].plot(grid=True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Financial Analysis\n",
    "In the rest of this section, I will explore returns, moving windows, volatility calculation and Ordinary Least-Squares Regression (OLS).\n",
    "\n",
    "### Returns\n",
    "The simple daily percentage doesn't take into account dividends and other factors and represents the amount of percentage change in the value of a stock over a single day of trading.\n",
    "\n",
    "Note I am calculating te log returns to get a better insight into the growth of the returns over the timeperiod."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign `Adj Close` to `daily_close`\n",
    "daily_close = aapl[['Adj. Close']]\n",
    "\n",
    "# Daily retuns \n",
    "daily_pct_c = daily_close.pct_change()\n",
    "\n",
    "# Replace NA values with 0\n",
    "daily_pct_c.fillna(0, inplace=True)\n",
    "\n",
    "# Inspect daily returns\n",
    "print(daily_pct_c)\n",
    "\n",
    "# Daily log returns\n",
    "daily_log_returns = np.log(daily_close.pct_change()+1)\n",
    "\n",
    "# Print daily log returns\n",
    "print(daily_log_returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample `aapl` to business months, take last observation as value \n",
    "monthly = aapl.resample('BM').apply(lambda x: x[-1])\n",
    "\n",
    "# Calculate the monthly percentage change\n",
    "monthly.pct_change()\n",
    "\n",
    "# Resample `aapl` to quarters, take the mean as value per quarter\n",
    "quarter = aapl.resample(\"4M\").mean()\n",
    "\n",
    "# Calculate the quarterly percentage change\n",
    "quarter.pct_change()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using pct_change() is quite the convenience, but it also obscures how exactly the daily percentages are calculated. That’s why you can alternatively make use of Pandas’ shift() function instead of using pct_change(). You then divide the daily_close values by the daily_close.shift(1) -1. By using this function, however, you will be left with NA values in the beginning of the resulting DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily returns\n",
    "daily_pct_c = daily_close / daily_close.shift(1) - 1\n",
    "\n",
    "# Print `daily_pct_c`\n",
    "print(daily_pct_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the distribution of `daily_pct_c`\n",
    "daily_pct_c.hist(bins=50)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# Pull up summary statistics\n",
    "print(daily_pct_c.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution looks very symmetrical and normally distributed: the daily changes centre approximately around 0.0. Using `.describe()` we can see that it is actually centred arounf 0.001567 and the standard deviation is 0.024."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **cumulative daily rated of return** is useful to determine the value of an investment at regular intervals. The daily rate of return can be calculated by using the daily percentage change values, adding 1 to them and calculating the cumulative product with the resulting values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ncumulatice daily returns\n",
    "cum_daily_return = (1 + daily_pct_c).cumprod()\n",
    "\n",
    "print(cum_daily_return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "cum_daily_return.plot(figsize=(12,8))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample the cumulative daily retunr to cumulaitve monthly return\n",
    "cum_monthly_return = cum_daily_return.resample(\"M\").mean()\n",
    "\n",
    "print(cum_monthly_return)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gather More Companies Data\n",
    "This will be done by writing a function that takes the symbol of the stock, start and end date. The nest function `data()` the takes the company symbol to get the data from the start date to the end date and returns it so that the `get()` function can continue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import quandl\n",
    "\n",
    "def get(tickers, startdate, enddate):\n",
    "    def data(ticker):\n",
    "        return (quandl.get(ticker, start_date=startdate, end_date=enddate))\n",
    "    datas = map (data, tickers)\n",
    "    return(pd.concat(datas, keys=tickers, names=['Ticker', 'Date']))\n",
    "tickers = ['WIKI/AAPL']\n",
    "#tickers = ['WIKI/AAPL', 'WIKI/MSFT', 'WIKI/IBM', 'WIKI/GOOG']\n",
    "all_data = get(tickers, datetime.datetime(2006, 10, 1), datetime.datetime(2012, 1, 1))\n",
    "all_data.sample(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function above only works for premium subscribers to quandl, as free users are not able to make concurrent calls. Therefore a modified function is below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import quandl\n",
    "def data(ticker, startdate, enddate):\n",
    "    return (quandl.get(ticker, start_date=startdate, end_date=enddate))\n",
    "\n",
    "\n",
    "def get(tickers, startdate, enddate):\n",
    "    datas = []\n",
    "    for ticker in tickers:\n",
    "        dat = data(ticker, startdate, enddate)\n",
    "        datas.append(dat) \n",
    "    return(pd.concat(datas, keys=tickers, names=['Ticker', 'Date']))\n",
    "\n",
    "tickers = ['WIKI/AAPL', 'WIKI/MSFT', 'WIKI/IBM', 'WIKI/GOOG']\n",
    "all_data = get(tickers, datetime.datetime(2006, 10, 1), datetime.datetime(2012, 1, 1))\n",
    "all_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Isolate the `Adj. Close` values and trasnform the dataframe\n",
    "daily_close_px = all_data[['Adj. Close']].reset_index().pivot('Date', \n",
    "                                                              'Ticker',\n",
    "                                                              'Adj. Close')\n",
    "\n",
    "# Calc the daily percentage change fro ` daily_close_px`\n",
    "daily_pct_change = daily_close_px.pct_change()\n",
    "\n",
    "daily_pct_change.hist(bins=50, sharex=True, figsize=(12,8))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A useful plot is the scatter matrix. This can be done easily by using the `pandas` library and the `scatter_matrix()` function. As arguments, I am passinf the `daily_pct_change` and as a diagonal, I am setting that I want to have a Kernel Density Estimate (KDE) plot. The Kernel Density Estimate plot estimates the probability density functionn of a randomb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plot a scatter matrix with the `daily_pct_change` data\n",
    "pd.plotting.scatter_matrix(daily_pct_change, diagonal='kde', alpha=0.1, \n",
    "                           figsize=(12,12))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving Windows\n",
    "Moving windows are there when you compute the statistic on a window of data represented by a particular period of time and then slide the window across the data by a specified interval.\n",
    "\n",
    "Pandas offers a lot of functions to calculate moving windows, such as `rolling_mean()`, `rolling_std()`,...\n",
    "\n",
    "However, these are soon to be depreciated, so instead a combination of the functions `rolling()` with `mean()` or `std()`.\n",
    "\n",
    "But what does a moving window exactly mean?\n",
    "\n",
    "The exact meaning depends on the statistic that you're applying to the data. For example, a rolling mean smoothes out short-term fluctuations and hightlights longer-term trends in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_close_px = aapl['Adj. Close']\n",
    "\n",
    "moving_avg = adj_close_px.rolling(window=40).mean()\n",
    "\n",
    "print(moving_avg[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# short moving window rolling mean\n",
    "aapl['42'] = adj_close_px.rolling(window=42).mean()\n",
    "\n",
    "# long moving window rolling mean\n",
    "aapl['252'] = adj_close_px.rolling(window=252).mean()\n",
    "\n",
    "# plot the adjusted closing price, the short and log windows of rolling\n",
    "# means\n",
    "aapl[['Adj. Close', '42', '252']].plot()\n",
    "\n",
    "# show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Volatility Calculation\n",
    "The volatility of a stock is a measurement of the change in variance in the returns of a stock over a specific period of time. It is common to compare the volatility of a stock with another stock to get a feel for which may have less risk or to a market index to examine the stock's volatility in the overall market. Generally, the higher the volatility, the riskier the investment in that stock, which results in investing in one over another.\n",
    "\n",
    "The moving historical standard deviation of the log returns - i.e. the moving historical volatility-might be more of interest: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# define the minimum number of periods to consider\n",
    "min_periods = 75\n",
    "\n",
    "# calculate volatility\n",
    "vol = daily_pct_change.rolling(min_periods).std() * np.sqrt(min_periods)\n",
    "\n",
    "vol.plot(figsize=(10,8))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The volatilty is calculated by taking a rolling window standard deviation on the percentagr change in a stock. \n",
    "\n",
    "Note that the size of the window can anf will change the overall result: if you take the window and make `min_periods` larger, your result will become less representative. If you make it smaller and make the window more narrow, the result will come closer to the standard deviation.\n",
    "\n",
    "Considering all of this, you see that it's definitely a skill to get the right window size based upon the data sampling frequency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ordinary Least-Squares Regression (OLS)\n",
    "After all of these calculations, I want to perform a more statistical analysis of the financial data, with more traditional regresssion analysis, such as Ordinary Least-Squares Regression (OLS).\n",
    "\n",
    "To do this, I am going to . ake use of the `statsmodels` library, which not only provides not only the ability to estimate statistical models but also to conduct statistical tests and perform data exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from pandas.core import datetools\n",
    "\n",
    "# isolate the adjusted closing price\n",
    "all_adj_close = all_data[['Adj. Close']]\n",
    "\n",
    "# calculate the returns\n",
    "all_returns = np.log(all_adj_close / all_adj_close.shift(1))\n",
    "\n",
    "# isolate the aapl returns\n",
    "aapl_returns = all_returns.iloc[all_returns.index.get_levels('Ticker') == 'AAPL']\n",
    "aapl_returns.index = aapl_returns.index.droplevle('Ticker')\n",
    "\n",
    "# isolate the msft returns\n",
    "msft_returns = all_returns.iloc[all_returns.index.get_level_values('Ticker') == 'MSFT']\n",
    "msft_returns.index = msft_returns.index.droplevel('Ticker')\n",
    "\n",
    "# build up a new dataframe with AAPL and MSFT\n",
    "return_data = pd.concat([aapl_returns, msft_returns], axis=1)[1:]\n",
    "return_data.columns = ['AAPL', 'MSFT']\n",
    "\n",
    "# add a constant\n",
    "X = sm.add_constant(return_data['AAPL'])\n",
    "\n",
    "# Construct the model\n",
    "model = sm.OLS(return_data['MSFT'],X).fit()\n",
    "\n",
    "# print the summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things to look out for when you're studying the result of the model summary are the following:\n",
    "\n",
    "* The ```Dep. Varibale```, which indicates which varaibale is the response in the model\n",
    "* The ```model``` in this case is ```OLS```. It's the model you're using in the fit.\n",
    "* Additionally, you also have the ```Method``` to indicate how the paramters of the model were calculated. In this case, you see that this is set at ```Least Squares```.\n",
    "\n",
    "Few other things that could be interesting:\n",
    "\n",
    "* The number of observations (```No. Observations```). Note that you could also derive this with the Pandas package by using the ```info()``` function. Run ```return_data.info()``` in the IPython console of the DataCamp Light chunch above to confirm this.\n",
    "\n",
    "* The degree of freedom of the residuals (```DF Residuals```)\n",
    "\n",
    "* The number of parameters in the model, indicated by ```DF Model```; Note that the number doesn't include the constant term ```X``` which was defined in the code above.\n",
    "\n",
    "* ```R-squared```, which is the coefficient of determination. This score indicates how well the regression line apporximates the real data points. In this case, the sult is 0.280. In percentages, this means that the score is at 28%. When the socr eis 0%, it indicates that the model explains none of the variablity of the response data around its mean. Of course, asocre of 100% indicates the opposite.\n",
    "\n",
    "* The ```F-statistic``` measures how significant the fit is. It is calculated by dividing the mean sqaured error of the model by the mean squared error of the residuals. The F-statistic for this model is 514.2.\n",
    "\n",
    "* Next, there's also the ```Prob(F-statisitc)```, which indicated the probability that you would get the result of the ```F-statistic```, given the null hypothesis that they are unrelated.\n",
    "\n",
    "* The ```Log-likelihood``` indicates the log of the likelihood function, which is, in this case 3513.2.\n",
    "\n",
    "* The ```AIC``` is the Akaike Infomration Criterion: this metric adjusts the log-likelihood based on the number of observations and the complexity of the model. The AIC of this model is -7022.\n",
    "\n",
    "* Lastly the ```BIC``` or Bayesian Information Criterion, is simlar to the AIC, mentioned above, but it penalizes models with more paramters more severely. Given the fact that this model only has one parameter, the BIC socre will be the same as the AIC score.\n",
    "\n",
    "Below the first part of the model summary, we get reports of each of the model's coefficients:\n",
    "\n",
    "* The estimated value of the coefficient is registered at ```coef```.\n",
    "\n",
    "* ```std err``` is the standard error of the estimate of the coefficient.\n",
    "\n",
    "* There's also the t-statistic vlaue, which you'll find under ```t```. The metric is used to measure how statistically significant a coefficient is.\n",
    "\n",
    "* ```P > |t|``` indicates the null-hypothesis that the coefficient = 0 is true. If it is less than the confidence level, often 0,05, it indicates that there is a statistically significant relationship between the term and the response. In this case, you see that the constant has a value of 0.198, while ```AAPL``` is set a 0.000.\n",
    "\n",
    "Lastly the final part of the model summary in which you see other statistical tests to assess the distribution of the residuals:\n",
    "\n",
    "* ```Omnibus```, which is the Omnibus D’Angostino’s test: it provides a combined statistical test for the presence of skewness and kurtosis.\n",
    "\n",
    "* The ```Prob(Omnibus)``` is the ```Omnibus``` metric turned into a probability.\n",
    "\n",
    "* Next, the ```Skew``` or Skewness measures the symmetry of the data about the mean.\n",
    "\n",
    "* The ```Kurtosis``` gives an indication of the shape of the distribution, as it compares the amount of data close to the mean with those far away from the mean (in the tails).\n",
    "\n",
    "* ```Durbin-Watson``` is a test for the presence of autocorrelation, and the ```Jarque-Bera``` is another test of the skewness and kurtosis. You can also turn the result of this test into a probability, as you can see in ```Prob (JB)```.\n",
    "\n",
    "* Lastly, you have the ```Cond. No```, which tests the multicollinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot returns of AAPL and MSFT\n",
    "plt.plot(return_data['AAPL'], return_data['MSFT'], 'r.')\n",
    "\n",
    "# Add an axis to the plot\n",
    "ax = plt.axis()\n",
    "\n",
    "# Initialize `x`\n",
    "x = np.linspace(ax[0], ax[1] + 0.01)\n",
    "\n",
    "# Plot the regression line\n",
    "plt.plot(x, model.params[0] + model.params[1] * x, 'b', lw=2)\n",
    "\n",
    "# Customize the plot\n",
    "plt.grid(True)\n",
    "plt.axis('tight')\n",
    "plt.xlabel('Apple Returns')\n",
    "plt.ylabel('Microsoft returns')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that you can also use the rolling correlation of returns as a way to crosscheck your results. You can handily make use of the Matplotlib integration with Pandas to call the plot() function on the results of the rolling correlation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the rolling correlation\n",
    "return_data['MSFT'].rolling(window=252).corr(return_data['AAPL']).plot()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building A Trading Strategy With Python"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
